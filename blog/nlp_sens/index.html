

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
      <title>CasADi - Blog - Sensitivities of parametric NLP</title>
    

    
    <link href="https://web.casadi.org/_css/font-awesome.min.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/bootstrap.min.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/pygments-default.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/casadi-theme.min.css" rel="stylesheet">

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ['\\(','\\)'] ],
          displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
          processEnvironments: false
        }
      });
    </script>

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
  </head>

  <body>



<nav class="navbar fixed-top navbar-expand-lg nav-top">
  <div class="container">
    <a class="navbar-brand" href="https://web.casadi.org/"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
      <i class="fa fa-bars" aria-hidden="true"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarNavDropdown">
      <ul class="navbar-nav">
        
        
          
          <li class="nav-item active">
          
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/get/">Try/Install</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/docs/">Docs</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/support/">Support</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/source/">Source</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/publications/">Publications</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/events/">Workshops</a>
          </li>
        
          
          <li class="nav-item active">
          
            <a class="nav-link" href="/blog/">Blog</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

<div id="main" class="container">
  <div class="row">
    <div class="col">
      <h1>Sensitivities of parametric NLP</h1>
      <span class="reading-time text-muted">Estimated reading time: 3 minutes</span>

      <p>In this post, we explore the parametric sensitivities of a nonlinear program (NLP).
While we use &lsquo;Opti stack&rsquo; syntax for modeling, differentiability of NLP solvers works all the same without Opti.</p>
<h1 id="parametric-nonlinear-programming">Parametric nonlinear programming</h1>
<p>Let&rsquo;s start by defining an NLP that depends on a parameter $p \in \mathbb{R}$ that should not be optimized for:
$$
\begin{align}
\displaystyle \underset{x,y}
{\text{minimize}}\quad &amp;\displaystyle (1-x)^2+0.2(y-x^2)^2 \newline
\text{subject to} \, \quad &amp; \frac{p^2}{4} \leq (x+0.5)^2+y^2 \leq p^2 \newline
&amp; x\geq 0
\end{align}
$$</p>
<p>For each choice of $p$, we have a different optimization problem, with a corresponding solution pair $(x^\star(p),y^\star(p))$.</p>
<p>The figure below visualizes this problem and its solution pair for three different values of $p$:</p>
<figure class=" default">
  <a href="https://web.casadi.org/blog/nlp_sens/nlp_1d.png" target="_blank">
  <img src="https://web.casadi.org/blog/nlp_sens/nlp_1d.png"  />
  </a>
  <figcaption>
    <h1>Parametric NLP visualized for different p</h1>
  </figcaption>
</figure>
<p>We&rsquo;d like to investigate how the NLP solution varies with $p$. To simplify visualization, let&rsquo;s consider a projection of the solution pair to a scalar:</p>
<p>$$
z: (x,y) \mapsto y-x
$$</p>
<p>Instead of working with the $x^\star$ notation, let&rsquo;s define the parametric solution function $M(p): \mathbb{R} \mapsto \mathbb{R}^2$:
$$
M(p):=
\begin{align}
\displaystyle \underset{x,y}
{\text{argmin}}\quad &amp;\displaystyle (1-x)^2+0.2(y-x^2)^2 \newline
\text{subject to} \, \quad &amp; \frac{p^2}{4} \leq (x+0.5)^2+y^2 \leq p^2 \newline
&amp; x\geq 0
\end{align}
$$</p>
<p>For a range of different $p$ values, we consider $z(M(p))$:</p>
<figure class=" default">
  <a href="https://web.casadi.org/blog/nlp_sens/nlp_sampled_1d.png" target="_blank">
  <img src="https://web.casadi.org/blog/nlp_sens/nlp_sampled_1d.png"  />
  </a>
  <figcaption>
    <h1>Parametric solution curve for sampled in p</h1>
  </figcaption>
</figure>
<p>Notice how the slope of the curve makes a jump. This happens when the set of active constraints changes.</p>
<p>The goal of the remainder is to obtain Taylor approximations of this curve, without resorting to sampling and finite differences.</p>
<h1 id="parametric-solution-as-casadi-function">Parametric solution as CasADi Function</h1>
<p>We use Opti to model the problem:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">opti</span> <span class="p">=</span> <span class="n">Opti</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="p">=</span> <span class="n">opti</span><span class="p">.</span><span class="n">variable</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="p">=</span> <span class="n">opti</span><span class="p">.</span><span class="n">variable</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">xy</span> <span class="p">=</span> <span class="p">[</span><span class="n">x</span><span class="p">;</span><span class="n">y</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="n">p</span> <span class="p">=</span> <span class="n">opti</span><span class="p">.</span><span class="n">parameter</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">opti</span><span class="p">.</span><span class="n">minimize</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>^<span class="mi">2</span> <span class="o">+</span> <span class="mf">0.2</span><span class="o">*</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">x</span>^<span class="mi">2</span><span class="p">)</span>^<span class="mi">2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">opti</span><span class="p">.</span><span class="n">subject_to</span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="p">=</span><span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">opti</span><span class="p">.</span><span class="n">subject_to</span><span class="p">((</span><span class="n">p</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>^<span class="mi">2</span> <span class="o">&lt;</span><span class="p">=</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mf">0.5</span><span class="p">)</span>^<span class="mi">2</span><span class="o">+</span><span class="n">y</span>^<span class="mi">2</span> <span class="o">&lt;</span><span class="p">=</span> <span class="n">p</span>^<span class="mi">2</span><span class="p">);</span>
</span></span></code></pre></div><p>We use <code>to_function</code> to represent the parametric solution function $M$ as a regular CasADi Function.
This Function has an Ipopt solver embedded.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">opts</span> <span class="p">=</span> <span class="n">struct</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">opts</span><span class="p">.</span><span class="n">ipopt</span><span class="p">.</span><span class="n">print_level</span> <span class="p">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">opts</span><span class="p">.</span><span class="n">print_time</span> <span class="p">=</span> <span class="n">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">opti</span><span class="p">.</span><span class="n">solver</span><span class="p">(</span><span class="s">&#39;ipopt&#39;</span><span class="p">,</span><span class="n">opts</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">M</span> <span class="p">=</span> <span class="n">opti</span><span class="p">.</span><span class="n">to_function</span><span class="p">(</span><span class="s">&#39;M&#39;</span><span class="p">,{</span><span class="n">p</span><span class="p">},{</span><span class="n">xy</span><span class="p">});</span>
</span></span></code></pre></div><p>With <code>M</code> in place, we can easily recreate the figure above by solving 100 Ipopt problems:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">z</span> <span class="p">=</span> <span class="p">@(</span><span class="n">xy</span><span class="p">)</span> <span class="n">xy</span><span class="p">(</span><span class="mi">2</span><span class="p">,:)</span><span class="o">-</span><span class="n">xy</span><span class="p">(</span><span class="mi">1</span><span class="p">,:);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pvec</span> <span class="p">=</span> <span class="nb">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">S</span> <span class="p">=</span> <span class="n">full</span><span class="p">(</span><span class="n">M</span><span class="p">(</span><span class="n">pvec</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plot</span><span class="p">(</span><span class="n">pvec</span><span class="p">,</span><span class="n">z</span><span class="p">(</span><span class="n">S</span><span class="p">));</span>
</span></span></code></pre></div><h1 id="parametric-sensitivities">Parametric sensitivities</h1>
<p>Ipopt is a very robust nonlinear optimizer: it finds solutions from bad initial guesses.
SQPMethod+QRQP is more fragile, but delivers more accuracy in dual variables when it converges. We make a combination of the two to obtain accurate sensitivity information.</p>
<p>Let&rsquo;s create a CasADi Function <code>Z</code> that computes the projected solution given <code>p</code> and an initial guess for decision variables.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">opts</span> <span class="p">=</span> <span class="n">struct</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">opts</span><span class="p">.</span><span class="n">qpsol</span> <span class="p">=</span> <span class="s">&#39;qrqp&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">opti</span><span class="p">.</span><span class="n">solver</span><span class="p">(</span><span class="s">&#39;sqpmethod&#39;</span><span class="p">,</span><span class="n">opts</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Z</span> <span class="p">=</span> <span class="n">opti</span><span class="p">.</span><span class="n">to_function</span><span class="p">(</span><span class="s">&#39;Z&#39;</span><span class="p">,{</span><span class="n">p</span><span class="p">,</span><span class="n">xy</span><span class="p">},{</span><span class="n">z</span><span class="p">(</span><span class="n">xy</span><span class="p">)});</span>
</span></span></code></pre></div><p>Calling that Function <code>Z</code> symbolically allows us to perform algorithmic differentiation on the resultant expression:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="n">zp</span> <span class="p">=</span> <span class="n">Z</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">xy</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="nb">j</span> <span class="p">=</span> <span class="n">jacobian</span><span class="p">(</span><span class="n">zp</span><span class="p">,</span><span class="n">p</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">h</span> <span class="p">=</span> <span class="n">hessian</span><span class="p">(</span><span class="n">zp</span><span class="p">,</span><span class="n">p</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">Z_taylor</span> <span class="p">=</span> <span class="n">Function</span><span class="p">(</span><span class="s">&#39;Z_taylor&#39;</span><span class="p">,{</span><span class="n">p</span><span class="p">,</span><span class="n">xy</span><span class="p">},{</span><span class="n">zp</span><span class="p">,</span><span class="nb">j</span><span class="p">,</span><span class="n">h</span><span class="p">});</span>
</span></span></code></pre></div><p>Evaluate <code>Z_taylor</code> numerically to be able to plot some nice second-order approximations onto the previous plot:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-matlab" data-lang="matlab"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">p0</span> <span class="p">=</span>  <span class="p">[</span><span class="mf">1.25</span><span class="p">,</span><span class="mf">1.4</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="n">F</span><span class="p">,</span><span class="n">J</span><span class="p">,</span><span class="n">H</span><span class="p">]</span> <span class="p">=</span> <span class="n">Z_taylor</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span><span class="n">M</span><span class="p">(</span><span class="n">p0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="n">plot</span><span class="p">(</span><span class="n">p_lin</span><span class="p">,</span><span class="n">full</span><span class="p">(</span><span class="n">F</span><span class="p">),</span><span class="s">&#39;x&#39;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">full</span><span class="p">(</span><span class="n">F</span><span class="o">+</span><span class="n">J</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">p0</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">H</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">p0</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="k">end</span>
</span></span></code></pre></div><figure class=" default">
  <a href="https://web.casadi.org/blog/nlp_sens/nlp_sens_1d.png" target="_blank">
  <img src="https://web.casadi.org/blog/nlp_sens/nlp_sens_1d.png"  />
  </a>
  <figcaption>
    <h1>Second-order approximations to parametric solution curve for different p</h1>
  </figcaption>
</figure>
<h1 id="conclusion">Conclusion</h1>
<p>We showed how to obtain first and second order sensitivities of the solution of a parametric NLP with respect to the parameter.
The example used a single scalar parameter, but can easily be extended to multiple parameters.
The rules of algorithmic differentiation apply: CasADi will just use one adjoint sweep to compute the full gradient for multiple parameters.</p>
<p>See <a href="https://www.sciencedirect.com/science/article/pii/S2405896318327137">our paper</a> for mathematical details on sensitivity analysis.</p>
<p>Download code: <a href="code_1d.m">code_1d.m</a>, <a href="plot_nlp.m">plot_nlp.m</a></p>

    </div>
  </div>
</div>
    <footer>
      <div class="container">
        <div class="row justify-content-md-center">
          <div class="col-md-auto text-center">
            <ul id="social" class="list-inline">
              
                <li class="list-inline-item">
                  <a href="https://github.com/casadi/casadi" title="github">
                    <i class="fa fa-github"></i>
                  </a>
                </li>
              
                <li class="list-inline-item">
                  <a href="https://twitter.com/casadi_software" title="twitter">
                    <i class="fa fa-twitter"></i>
                  </a>
                </li>
              
                <li class="list-inline-item">
                  <a href="https://www.youtube.com/channel/UC3VDpv5Pi3R-a2VkcJN1RLw" title="youtube">
                    <i class="fa fa-youtube"></i>
                  </a>
                </li>
              
            </ul>
            <p class="copyright">Copyright 2023.</p>
          </div>
        </div>
      </div>
    </footer>

    
    <script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

    
    <script src="https://web.casadi.org/_js/bootstrap.min.js"></script>

    
    <script src="https://web.casadi.org/_js/scripts.js"></script>

    
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML">
</script>

    
  </body>

</html>

