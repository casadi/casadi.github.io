

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
      <title>CasADi - Blog - Tensorflow and CasADi</title>
    

    
    <link href="https://web.casadi.org/_css/font-awesome.min.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/bootstrap.min.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/pygments-default.css" rel="stylesheet">

    
    <link href="https://web.casadi.org/_css/casadi-theme.min.css" rel="stylesheet">

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ['\\(','\\)'] ],
          displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
          processEnvironments: false
        }
      });
    </script>

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
  </head>

  <body>



<nav class="navbar fixed-top navbar-expand-lg nav-top">
  <div class="container">
    <a class="navbar-brand" href="https://web.casadi.org/"></a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
      <i class="fa fa-bars" aria-hidden="true"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarNavDropdown">
      <ul class="navbar-nav">
        
        
          
          <li class="nav-item active">
          
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/get/">Try/Install</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/docs/">Docs</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/support/">Support</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/source/">Source</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/publications/">Publications</a>
          </li>
        
          
          <li class="nav-item">
          
            <a class="nav-link" href="/events/">Workshops</a>
          </li>
        
          
          <li class="nav-item active">
          
            <a class="nav-link" href="/blog/">Blog</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

<div id="main" class="container">
  <div class="row">
    <div class="col">
      <h1>Tensorflow and CasADi</h1>
      <span class="reading-time text-muted">Estimated reading time: 5 minutes</span>

      

<p>In this post we'll explore how to couple <a href="https://www.tensorflow.org">Tensorflow</a> and CasADi.
Thanks to Jonas Koch (student @ Applied Mathematics WWU Muenster) for delivering inspiration and example code.</p>

<h1 id="one-dimensional-regression-with-gpflow">One-dimensional regression with GPflow</h1>

<p>An important part of machine learning is about regression: fitting a (non-)linear model through sparse data.
This is an unconstrained optimization problem for which dedicated algorithms and software are readily available.</p>

<p>Let's create some datapoints to fit, a perturbed sine.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,(</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span></code></pre></div>
<p>We make use of <a href="https://github.com/GPflow/GPflow">GPflow</a>, software which is built on top of <a href="https://www.tensorflow.org">Tensorflow</a>, to perform a Gaussian process regression:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">White</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">gpflow</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ScipyOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></code></pre></div>
<p>The trained model has a <code>predict_y</code> method to deliver us the mean and variance of the fit at any location(s):</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="o">*</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="p">[</span><span class="n">mean</span><span class="p">,</span><span class="n">variance</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">xf</span><span class="p">)</span></code></pre></div>

<figure class=" default">
  <a href="https://web.casadi.org/blog/tensorflow/gpflow1d.png" target="_blank">
  
    <img src="https://web.casadi.org/blog/tensorflow/gpflow1d.png"  />
  </a>
  
  <figcaption>
    <h1>1D regression example with GPflow</h1>
    
  </figcaption>
  
</figure>



<h1 id="embedding-the-regression-model-in-a-casadi-graph">Embedding the regression model in a CasADi graph</h1>

<p>The mechanism for embedding foreign code in CasADi is through the use of a <a href="http://docs.casadi.org/#subclassing-callback">Callback</a>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">GPR</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>  <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
    <span class="n">Callback</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">construct</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
    <span class="p">[</span><span class="n">mean</span><span class="p">,</span><span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">mean</span><span class="p">]</span></code></pre></div>
<p>After instantiating the Callback, we end up with a plain-old CasADi function object which we can evaluate numerically or symbolically.
One caveat, the user is responsible of keeping at least one reference to this Function.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">gpr</span> <span class="o">=</span> <span class="n">GPR</span><span class="p">(</span><span class="s1">&#39;GPR&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&#34;enable_fd&#34;</span><span class="p">:</span><span class="bp">True</span><span class="p">})</span></code></pre></div>
<p>As an example of embedding, we can ask Ipopt to compute the minimum of this function.
Finite differences will be used to differentiate the Callback:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">x</span> <span class="o">=</span> <span class="n">MX</span><span class="o">.</span><span class="n">sym</span><span class="p">(</span><span class="s2">&#34;x&#34;</span><span class="p">)</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">nlpsol</span><span class="p">(</span><span class="s2">&#34;solver&#34;</span><span class="p">,</span><span class="s2">&#34;ipopt&#34;</span><span class="p">,{</span><span class="s2">&#34;x&#34;</span><span class="p">:</span><span class="n">x</span><span class="p">,</span><span class="s2">&#34;f&#34;</span><span class="p">:</span><span class="n">gpr</span><span class="p">(</span><span class="n">x</span><span class="p">)})</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">solver</span><span class="p">(</span><span class="n">x0</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code></pre></div>

<figure class=" default">
  <a href="https://web.casadi.org/blog/tensorflow/gpflow1d_min.png" target="_blank">
  
    <img src="https://web.casadi.org/blog/tensorflow/gpflow1d_min.png"  />
  </a>
  
  <figcaption>
    <h1>1D regression example with GPflow</h1>
    
  </figcaption>
  
</figure>



<p>Download code: <a href="gpflow_example.py">gpflow_example.py</a></p>

<h1 id="optimal-control-example-slow">Optimal control example (slow)</h1>

<p>The GPR model from the previous paragraph was a mapping from $R$ to $R$.
To make things more interesting, we will increase the dimension to a mapping from $R^\textrm{nd}$ to $R$.</p>

<p>I didn't have much inspiration to come up with high-dimensional data to fit, so these random arrays will have to do.
Of course, it's rather silly to fit a model through purely random data..</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">nd</span><span class="p">))</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">nd</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nd</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">White</span><span class="p">(</span><span class="n">nd</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">nd</span><span class="p">))</span></code></pre></div>
<p>Our callback will need to override the default-scalar sparsity for its input:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">GPR</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>  <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
    <span class="o">...</span>

  <span class="k">def</span> <span class="nf">get_sparsity_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">i</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">Sparsity</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">nd</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span></code></pre></div>
<p>For the remainder, we will just use the code of CasADi's <code>direct_multiple_shooting</code> example, but the solver construction is modified as follows.
The objective is replace by our nd-dimensional model evaluated on the concatenation of all x-states over the optimal control horizon.
We use a limited-memory Hessian approximation here to avoid the cost of obtaining second-order sensitivities.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">w</span> <span class="o">=</span> <span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="n">w</span><span class="p">)</span>

<span class="n">prob</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;f&#39;</span><span class="p">:</span> <span class="n">gpr</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">3</span><span class="p">]),</span> <span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">w</span> <span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">:</span> <span class="n">vertcat</span><span class="p">(</span><span class="o">*</span><span class="n">g</span><span class="p">)}</span>
<span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;ipopt&#34;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&#34;hessian_approximation&#34;</span><span class="p">:</span> <span class="s2">&#34;limited-memory&#34;</span><span class="p">}}</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">nlpsol</span><span class="p">(</span><span class="s1">&#39;solver&#39;</span><span class="p">,</span> <span class="s1">&#39;ipopt&#39;</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span><span class="n">options</span><span class="p">);</span></code></pre></div>
<p>The problem takes quite some time to solve.
If you look at the timings printout, you'll see that in particular the cost of computing the gradient of the objective (<code>nlp_grad_f</code>) is excessive:</p>
<div class="highlight"><pre class="chroma">               t_proc [s]   t_wall [s]    n_eval
       nlp_f        0.291        0.261        31
       nlp_g       0.0079      0.00789        31
  nlp_grad_f         25.7         23.2        32
   nlp_jac_g       0.0496       0.0502        32
      solver         26.2         23.6         1</pre></div>
<p>If you insert a print statement to inspect the arguments at our Callback's <code>eval</code> method, you'll see the finite differences happening live in your terminal:
each of the <code>nd</code> inputs to <code>gpr</code> is individually perturbed, making the cost to compute the gradient of the objective <code>nd</code> times more expensive than the cost of just the objective.</p>

<p>The solution requires 2783 calls to our Callback, and the Callback ran for a total of 21.7 seconds.</p>


<figure class=" default">
  <a href="https://web.casadi.org/blog/tensorflow/ocp.png" target="_blank">
  
    <img src="https://web.casadi.org/blog/tensorflow/ocp.png"  />
  </a>
  
  <figcaption>
    <h1>Optimal control example (slow)</h1>
    
  </figcaption>
  
</figure>



<p>Download code: <a href="ocp.py">ocp.py</a></p>

<h1 id="optimal-control-example-fast">Optimal control example (fast)</h1>

<p>We'll speed up our code on two fronts:</p>

<p>First, we notice that <code>predict_y</code> incurs quite some overhead. Instead of calling it repeatedly, let's work with the underlying Tensorflow graphs:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">nd</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="p">[</span><span class="n">mean</span><span class="p">,</span><span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_build_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code></pre></div>
<p>Running this <code>mean</code> graph in a tensorflow session has much less overhead:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">...</span><span class="p">)))</span></code></pre></div>
<p>Second, we notice that tensorflow supports algorithmic differentation.
If we add a reverse mode implementation to our Callback, we can get the gradient for (a small multiple of) the cost of the objective.
Note that (vanilla) Tensorflow offers only the reverse mode of AD, not the forward mode.
This is logical, since it focusses on unconstrained optimization.</p>

<p>It's quite easy to create a general purpose <code>TensorFlowEvaluator</code> Callback (<a href="tensorflow_casadi.py">tensorflow_casadi.py</a> for full code):</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">TensorFlowEvaluator</span><span class="p">(</span><span class="n">casadi</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">t_in</span><span class="p">,</span><span class="n">t_out</span><span class="p">,</span><span class="n">session</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
    <span class="o">....</span>

  <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">arg</span><span class="p">):</span>
    <span class="c1"># Associate each tensorflow input with the numerical argument passed by CasADi</span>
    <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">v</span><span class="p">,</span><span class="n">arg</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_in</span><span class="p">))</span>
    <span class="c1"># Evaluate the tensorflow expressions</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_out</span><span class="p">,</span><span class="n">feed_dict</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span>

  <span class="k">def</span> <span class="nf">has_reverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">nadj</span><span class="p">):</span> <span class="k">return</span> <span class="n">nadj</span><span class="o">==</span><span class="mi">1</span>
  <span class="k">def</span> <span class="nf">get_reverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">nadj</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">inames</span><span class="p">,</span><span class="n">onames</span><span class="p">,</span><span class="n">opts</span><span class="p">):</span>
    <span class="c1"># Construct tensorflow placeholders for the reverse seeds</span>
    <span class="n">adj_seed</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparsity_out</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_out</span><span class="p">())]</span>
    <span class="c1"># Construct the reverse tensorflow graph through &#39;gradients&#39;</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_in</span><span class="p">,</span><span class="n">grad_ys</span><span class="o">=</span><span class="n">adj_seed</span><span class="p">)</span>
    <span class="c1"># Create another TensorFlowEvaluator object</span>
    <span class="n">callback</span> <span class="o">=</span> <span class="n">TensorFlowEvaluator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">t_in</span><span class="o">+</span><span class="n">adj_seed</span><span class="p">,</span><span class="n">grad</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">)</span>
    <span class="o">...</span></code></pre></div>
<p>With these two modifications in place, the solution requires just 63 calls to our Callback, for a total Callback runtime of 0.13 seconds.</p>

<p>Download code: <a href="ocp_faster.py">ocp_faster.py</a>, <a href="tensorflow_casadi.py">tensorflow_casadi.py</a></p>

<p>In conclusion, we've shown how to embed calls to foreign code in CasADi graphs.
Though the optimal control example is contrived, it conveys how such coupling can be made efficient.</p>

<p>To learn more ways to endow sensitivity-information on a Callback, see the <a href="https://github.com/casadi/casadi/blob/develop/docs/examples/python/callback.py">callback.py example</a>.</p>

    </div>
  </div>
</div>
    <footer>
      <div class="container">
        <div class="row justify-content-md-center">
          <div class="col-md-auto text-center">
            <ul id="social" class="list-inline">
              
                <li class="list-inline-item">
                  <a href="https://github.com/casadi/casadi" title="github">
                    <i class="fa fa-github"></i>
                  </a>
                </li>
              
                <li class="list-inline-item">
                  <a href="https://twitter.com/casadi_software" title="twitter">
                    <i class="fa fa-twitter"></i>
                  </a>
                </li>
              
                <li class="list-inline-item">
                  <a href="https://www.youtube.com/channel/UC3VDpv5Pi3R-a2VkcJN1RLw" title="youtube">
                    <i class="fa fa-youtube"></i>
                  </a>
                </li>
              
            </ul>
            <p class="copyright">Copyright 2018.</p>
          </div>
        </div>
      </div>
    </footer>

    
    <script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

    
    <script src="https://web.casadi.org/_js/bootstrap.min.js"></script>

    
    <script src="https://web.casadi.org/_js/scripts.js"></script>

    
    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML">
</script>

    
  </body>

</html>

